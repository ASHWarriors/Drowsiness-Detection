{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeCascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "leyeCascade = cv2.CascadeClassifier(\"haarcascade_lefteye_2splits.xml\")\n",
    "reyeCascade = cv2.CascadeClassifier(\"haarcascade_righteye_2splits.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 98, 98, 200)       2000      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 98, 98, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 49, 49, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 47, 47, 100)       180100    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 47, 47, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                2645050   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 2,827,252\n",
      "Trainable params: 2,827,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('yaw-yaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 98, 98, 200)       2000      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 98, 98, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 49, 49, 200)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 47, 47, 100)       180100    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 47, 47, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                2645050   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 2,827,252\n",
      "Trainable params: 2,827,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alarmer():  # Alarm triggered every time fatigued user detected.\n",
    "    ti1 = time()\n",
    "    mixer.init()\n",
    "    mixer.music.load(\"alarm1.mp3\")\n",
    "    mixer.music.set_volume(0.7)\n",
    "    mixer.music.play()\n",
    "    return ti1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(10,100)\n",
    "blink_count = 0\n",
    "blink_status = 0\n",
    "t1 = t1_ = time()\n",
    "wake = 1\n",
    "sleep = 0\n",
    "yawn_count = 0\n",
    "yawn_status = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(imgGray,1.1,4)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        gray_face=imgGray[y:y+h,x:x+w]\n",
    "        color_face=img[y:y+h,x:x+w]\n",
    "        resized_image = cv2.resize(gray_face, (100, 100))\n",
    "        reshaped_face = np.reshape(resized_image, (1, 100, 100, 1))\n",
    "        predyawn = model1.predict(reshaped_face)\n",
    "        if predyawn[0][0] < predyawn[0][1]:\n",
    "            if yawn_status == 0:\n",
    "                yawn_count += 1\n",
    "                yawn_status = 1\n",
    "        else: \n",
    "            yawn_status = 0\n",
    "        \n",
    "        eye = eyeCascade.detectMultiScale(gray_face,1.3,5)\n",
    "        leye = leyeCascade.detectMultiScale(gray_face,1.3,5)\n",
    "        reye = reyeCascade.detectMultiScale(gray_face,1.3,5)\n",
    "        \n",
    "        for (a,b,c,d) in leye:\n",
    "            cv2.rectangle(color_face,(a,b),(a+c,b+d),(0,255,0),2)\n",
    "            l_eye = color_face[b:b+d,a:a+c]\n",
    "            resized_image = cv2.resize(l_eye, (100, 100))\n",
    "            l_eye = cv2.cvtColor(resized_image,cv2.COLOR_BGR2GRAY)\n",
    "            #normalized_image = l_eye/255\n",
    "            reshaped_eye = np.reshape(l_eye, (1, 100, 100, 1))\n",
    "            lpred = model.predict(reshaped_eye)\n",
    "                     \n",
    "        for (a,b,c,d) in reye:\n",
    "            cv2.rectangle(color_face,(a,b),(a+c,b+d),(0,255,0),2)\n",
    "            r_eye = color_face[b:b+d,a:a+c]\n",
    "            resized_image = cv2.resize(r_eye, (100, 100))\n",
    "            r_eye = cv2.cvtColor(resized_image,cv2.COLOR_BGR2GRAY)\n",
    "            #normalized_image = l_eye/255\n",
    "            reshaped_eye = np.reshape(r_eye, (1, 100, 100, 1))\n",
    "            rpred = model.predict(reshaped_eye)\n",
    "            \n",
    "        \n",
    "        if rpred[0][0] < rpred[0][1] and lpred[0][0] < lpred[0][1]:\n",
    "            if blink_status == 0:\n",
    "                blink_count += 1\n",
    "                blink_status = 1\n",
    "        else: \n",
    "            blink_status = 0\n",
    " \n",
    " #Eye blink frequency \n",
    "    t2 = time()\n",
    "    count_down = t2 - t1\n",
    "    #10 count = 4,   count n= 1\n",
    "    if count_down >= 15:\n",
    "        if blink_count > 4:\n",
    "            wake = 1\n",
    "        else:\n",
    "            wake = 0     \n",
    "        t1 = time()\n",
    "        blink_count = 0\n",
    "        \n",
    "    elapsed_time = t2 - t1_ \n",
    "    if elapsed_time >= 10:\n",
    "        if yawn_count > 1:\n",
    "            sleep = 1\n",
    "        elif yawn_count == 1:\n",
    "            sleep = 0.5\n",
    "        else:\n",
    "            sleep = 0\n",
    "        t1_ = time()\n",
    "        yawn_count = 0    \n",
    "     \n",
    "\n",
    "        \n",
    "    cv2.putText(img,'Yawns = ' + str(yawn_count) + ', Blinks = ' + str(blink_count),(x, y - 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "    if sleep == 1: \n",
    "        from pygame import mixer\n",
    "        ti1 = alarmer()\n",
    "        cv2.putText(img,\"Fatigued\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        ti2 = time()\n",
    "        if ti2 - ti1 >= 15:\n",
    "            mixer.music.stop()\n",
    "    elif not wake and sleep == 0.5:\n",
    "        cv2.putText(img,\"Semi Fatigued\",(x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (57, 143, 235), 2)\n",
    "    elif wake and sleep == 0.5:\n",
    "        cv2.putText(img,\"Drowsy\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (58, 238, 238), 2)\n",
    "    elif wake:\n",
    "        cv2.putText(img,\"Awake\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (67, 146, 52), 2)\n",
    "    else:\n",
    "        cv2.putText(img,\"Semi Drowsy\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (57, 235, 143), 2)\n",
    "   \n",
    "            \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "mixer.music.stop()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}






