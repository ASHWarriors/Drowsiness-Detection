{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "knhQMXyVadPg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9wgEQzoadPo",
    "outputId": "bce2a1cf-e10e-449e-86c6-381bcfb155c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from 'C:\\\\Users\\\\Sristi\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qSwJq6SPadPq"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'E:/DrowsyBrowsy/archive/Eye Dataset/Train_Data'\n",
    "TEST_DIR = 'E:/DrowsyBrowsy/archive/Eye Dataset/Test_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a52SRJLncJwh",
    "outputId": "a5d7fada-242c-48f8-8bf7-e333ffbd30b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/DrowsyBrowsy/archive/Eye Dataset/Train_Data\n"
     ]
    }
   ],
   "source": [
    "print(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5lKm4BfDadPs"
   },
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('_')[4]\n",
    "    if word_label[0] == '1': return [1,0] \n",
    "    elif word_label[0] == '0': return [0,1]\n",
    "    \n",
    "    #1 eyes are open\n",
    "    #0 eyes are closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eLYrdY5PadPt"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "fjU5h51sadPu"
   },
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img, (100, 100))\n",
    "        X_train.append(np.array(resized_img))\n",
    "        Y_train += [label]\n",
    "        \n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "w-MpFDL_adPv",
    "outputId": "2de03a75-b149-48e4-d430-b82ab69e320d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32623/32623 [00:20<00:00, 1600.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "Y_train = np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32623"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32623"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32623, 100, 100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "60TU54kfadPx"
   },
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        resized_img = cv2.resize(img, (100, 100))\n",
    "        X_test.append(np.array(resized_img))\n",
    "        Y_test += [label]\n",
    "        \n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "uzvLwWKOadP1",
    "outputId": "d72aace0-e147-4e74-a93c-151f694ddbcb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14550/14550 [00:06<00:00, 2105.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test)\n",
    "Y_test = np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ISyb0cNradP3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "5EvZeW-vadP4"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "KdKIVqR3adP6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32623, 100, 100, 1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32623, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(32623, 100, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(32623,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "ifInBZ-gadP6"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(200, (3,3), input_shape=(100, 100, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(100, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "pkOCKfH1adP7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "816/816 [==============================] - 1624s 2s/step - loss: 3.5319 - accuracy: 0.8427 - val_loss: 0.5339 - val_accuracy: 0.6771\n",
      "INFO:tensorflow:Assets written to: model-best\\assets\n",
      "Epoch 2/6\n",
      "816/816 [==============================] - 1609s 2s/step - loss: 0.2323 - accuracy: 0.9149 - val_loss: 0.2158 - val_accuracy: 0.9350\n",
      "INFO:tensorflow:Assets written to: model-best\\assets\n",
      "Epoch 3/6\n",
      "816/816 [==============================] - 1502s 2s/step - loss: 0.1823 - accuracy: 0.9334 - val_loss: 0.2348 - val_accuracy: 0.9318\n",
      "Epoch 4/6\n",
      "816/816 [==============================] - 1485s 2s/step - loss: 0.3161 - accuracy: 0.8792 - val_loss: 0.6507 - val_accuracy: 0.6703\n",
      "Epoch 5/6\n",
      "816/816 [==============================] - 1452s 2s/step - loss: 0.5594 - accuracy: 0.7527 - val_loss: 0.6549 - val_accuracy: 0.6703\n",
      "Epoch 6/6\n",
      "816/816 [==============================] - 1466s 2s/step - loss: 0.5562 - accuracy: 0.7556 - val_loss: 0.6537 - val_accuracy: 0.6703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c908db9af0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = ModelCheckpoint('model-best', verbose=0, save_best_only=True)\n",
    "model.fit(X_train, Y_train, epochs = 6,callbacks=[cp], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeCascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "leyeCascade = cv2.CascadeClassifier(\"haarcascade_lefteye_2splits.xml\")\n",
    "reyeCascade = cv2.CascadeClassifier(\"haarcascade_righteye_2splits.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model-best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('yaw-yaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(10,100)\n",
    "blink_count = 0\n",
    "blink_status = 0\n",
    "t1 = t1_ = time()\n",
    "wake = 1\n",
    "sleep = 0\n",
    "yawn_count = 0\n",
    "yawn_status = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(imgGray,1.1,4)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        gray_face=imgGray[y:y+h,x:x+w]\n",
    "        color_face=img[y:y+h,x:x+w]\n",
    "        resized_image = cv2.resize(gray_face, (100, 100))\n",
    "        reshaped_face = np.reshape(resized_image, (1, 100, 100, 1))\n",
    "        predyawn = model1.predict(reshaped_face)\n",
    "        \n",
    "        eye = eyeCascade.detectMultiScale(gray_face,1.3,5)\n",
    "        leye = leyeCascade.detectMultiScale(gray_face,1.3,5)\n",
    "        reye = reyeCascade.detectMultiScale(gray_face,1.3,5)\n",
    "        \n",
    "        for (a,b,c,d) in leye:\n",
    "            cv2.rectangle(color_face,(a,b),(a+c,b+d),(0,255,0),2)\n",
    "            l_eye = color_face[b:b+d,a:a+c]\n",
    "            resized_image = cv2.resize(l_eye, (100, 100))\n",
    "            l_eye = cv2.cvtColor(resized_image,cv2.COLOR_BGR2GRAY)\n",
    "            #normalized_image = l_eye/255\n",
    "            reshaped_eye = np.reshape(l_eye, (1, 100, 100, 1))\n",
    "            lpred = model.predict(reshaped_eye)\n",
    "                     \n",
    "        for (a,b,c,d) in reye:\n",
    "            cv2.rectangle(color_face,(a,b),(a+c,b+d),(0,255,0),2)\n",
    "            r_eye = color_face[b:b+d,a:a+c]\n",
    "            resized_image = cv2.resize(r_eye, (100, 100))\n",
    "            r_eye = cv2.cvtColor(resized_image,cv2.COLOR_BGR2GRAY)\n",
    "            #normalized_image = l_eye/255\n",
    "            reshaped_eye = np.reshape(r_eye, (1, 100, 100, 1))\n",
    "            rpred = model.predict(reshaped_eye)\n",
    "            \n",
    "        \n",
    "        if rpred[0][0] < rpred[0][1] and lpred[0][0] < lpred[0][1]:\n",
    "            if blink_status == 0:\n",
    "                blink_count += 1\n",
    "                blink_status = 1\n",
    "        else: \n",
    "            blink_status = 0\n",
    " \n",
    " #Eye blink frequency \n",
    "    t2 = time()\n",
    "    count_down = t2 - t1\n",
    "    #10 count = 4,   count n= 1\n",
    "    if count_down >= 15:\n",
    "        if blink_count > 4:\n",
    "            wake = 1\n",
    "        else:\n",
    "            wake = 0     \n",
    "        t1 = time()\n",
    "        blink_count = 0\n",
    "        \n",
    "    elapsed_time = t2 - t1_ \n",
    "    if elapsed_time >= 10:\n",
    "        if yawn_count > 1:\n",
    "            sleep = 1\n",
    "        elif yawn_count == 1:\n",
    "            sleep = 0.5\n",
    "        else:\n",
    "            sleep = 0\n",
    "        t1_ = time()\n",
    "        yawn_count = 0    \n",
    "     \n",
    "    if predyawn[0][0] < predyawn[0][1]:\n",
    "        if yawn_status == 0:\n",
    "            yawn_count += 1\n",
    "            yawn_status = 1\n",
    "    else: \n",
    "        yawn_status = 0\n",
    "        \n",
    "    cv2.putText(img,'Yawns = ' + str(yawn_count) + ', Blinks = ' + str(blink_count),(x, y - 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "        # Awake # Very Awake \n",
    "    if sleep == 1: # red orange yellow\n",
    "        cv2.putText(img,\"Fatigued\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    elif not wake and sleep == 0.5:\n",
    "        cv2.putText(img,\"Semi Fatigued\",(x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (57, 143, 235), 2)\n",
    "    elif wake and sleep == 0.5:\n",
    "        cv2.putText(img,\"Drowsy\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (58, 238, 238), 2)\n",
    "    elif wake:\n",
    "        cv2.putText(img,\"Awake\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (67, 146, 52), 2)\n",
    "    else:\n",
    "        cv2.putText(img,\"Semi Drowsy\",(x+50, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (57, 235, 143), 2)\n",
    "   \n",
    "            \n",
    "    cv2.imshow(\"Result\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Blinky.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
